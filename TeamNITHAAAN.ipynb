{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (5, 10, 68, 2)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('new_new_data.npy')\n",
    "print('Shape: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "image = mpimg.imread(\"landmark_lavar.PNG\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "image = mpimg.imread(\"lebron_landmark.PNG\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "image = mpimg.imread(\"bush_landmark.PNG\")\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "changed = StandardScaler()\n",
    "changed.fit(data.reshape(50*68, 2))\n",
    "new_data = changed.transform(data.reshape(50*68, 2))\n",
    "normalized = normalize(data.reshape(50, 68, 2).reshape(50*68,2))\n",
    "standard_normalized = normalize(new_data)\n",
    "\n",
    "#new_data = new_data.reshape(50, 68, 2).reshape(5, 10, 68, 2)\n",
    "new_normalized = normalized.reshape(50, 68, 2).reshape(5,10, 68, 2)\n",
    "standard_normalized = standard_normalized.reshape(50, 68, 2).reshape(5,10, 68, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1a81d7f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def normPointPlotter(coords):\n",
    "    img = np.ones((100, 100))\n",
    "    for x,y in coords.astype(int):\n",
    "        img[round(y), round(x)] = 0\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    plt.show()\n",
    "\n",
    "normPointPlotter(new_normalized[1, 3, :, :]*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6901"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (136,)\n",
    "left_input = Input(input_shape, name = 'left')\n",
    "right_input = Input(input_shape, name = 'right')\n",
    "\n",
    "convnet = Sequential()\n",
    "convnet.add(Dense(50,activation=\"relu\"))\n",
    "\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "prediction = Dense(1,activation='softmax')(L1_distance)\n",
    "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "\n",
    "optimizer = Adam(lr = 0.05)\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "\n",
    "siamese_net.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppl = 5\n",
    "imgs = 10\n",
    "img_names = []\n",
    "for i in range(ppl):\n",
    "    for j in range(imgs):\n",
    "        img_names.append([i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "[[[0, 0], [0, 0]], [[0, 0], [0, 1]], [[0, 0], [0, 2]], [[0, 0], [0, 3]], [[0, 0], [0, 4]], [[0, 0], [0, 5]], [[0, 0], [0, 6]], [[0, 0], [0, 7]], [[0, 0], [0, 8]], [[0, 0], [0, 9]], [[0, 0], [1, 0]], [[0, 0], [1, 1]], [[0, 0], [1, 2]], [[0, 0], [1, 3]], [[0, 0], [1, 4]], [[0, 0], [1, 5]], [[0, 0], [1, 6]], [[0, 0], [1, 7]], [[0, 0], [1, 8]], [[0, 0], [1, 9]]]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from random import shuffle\n",
    "\n",
    "ax = [[*p] for p in itertools.product(img_names, repeat=2)]\n",
    "print(len(ax))\n",
    "print(ax[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test = train_test_split( ax, test_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1-----Loss: 1.594239\n",
      "Epoch2-----Loss: 1.594239\n",
      "Epoch3-----Loss: 1.594239\n",
      "Epoch4-----Loss: 1.594239\n",
      "Epoch5-----Loss: 1.594239\n",
      "Epoch6-----Loss: 1.594239\n",
      "Epoch7-----Loss: 1.594239\n",
      "Epoch8-----Loss: 1.594239\n",
      "Epoch9-----Loss: 1.594239\n",
      "Epoch10-----Loss: 1.594239\n",
      "Epoch11-----Loss: 1.594239\n",
      "Epoch12-----Loss: 1.594239\n",
      "Epoch13-----Loss: 1.594239\n",
      "Epoch14-----Loss: 1.594239\n",
      "Epoch15-----Loss: 1.594239\n",
      "Epoch16-----Loss: 1.594239\n",
      "Epoch17-----Loss: 1.594239\n",
      "Epoch18-----Loss: 1.594239\n",
      "Epoch19-----Loss: 1.594239\n",
      "Epoch20-----Loss: 1.594239\n",
      "Epoch21-----Loss: 1.594239\n",
      "Epoch22-----Loss: 1.594239\n",
      "Epoch23-----Loss: 1.594239\n",
      "Epoch24-----Loss: 1.594239\n",
      "Epoch25-----Loss: 1.594239\n",
      "Epoch26-----Loss: 1.594239\n",
      "Epoch27-----Loss: 1.594239\n",
      "Epoch28-----Loss: 1.594239\n",
      "Epoch29-----Loss: 1.594239\n",
      "Epoch30-----Loss: 1.594239\n",
      "Epoch31-----Loss: 1.594239\n",
      "Epoch32-----Loss: 1.594239\n",
      "Epoch33-----Loss: 1.594239\n",
      "Epoch34-----Loss: 1.594239\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d9fe6c66d6a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch%s-----Loss: %f'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0msiamese_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msiamese_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-d9fe6c66d6a2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, labels, network, epochs, batch_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m              \u001b[0;34m'left'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m              \u001b[0;34m'right'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             },targets)\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtrack_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Epoch%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;31m# hack for list_devices() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   4969\u001b[0m       \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilding_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4970\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_DefaultGraphStack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_controller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4971\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4972\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4973\u001b[0m       \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   4784\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enforce_nesting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4786\u001b[0;31m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4787\u001b[0m             raise AssertionError(\n\u001b[1;32m   4788\u001b[0m                 \u001b[0;34m\"Nesting violated for default stack of %s objects\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(data, labels, network, epochs, batch_size):\n",
    "    track_loss  = defaultdict(list)\n",
    "    \n",
    "    for i in range(0, epochs):\n",
    "        iterations = len(labels)//batch_size\n",
    "        remain = len(labels)%batch_size\n",
    "        shuffle(labels)\n",
    "        avg_loss = 0.0\n",
    "        for j in range(0, iterations):\n",
    "            batch = [j*batch_size, j*batch_size + batch_size]\n",
    "            if(j == iterations - 1):\n",
    "                batch[1] += remain\n",
    "            mini_batch = np.zeros(shape = (batch[1] - batch[0], 2, 136))\n",
    "            for k in range(batch[0], batch[1]):\n",
    "                student1 = data[labels[k][0][0],labels[k][0][1],:,:]\n",
    "                student2 = data[labels[k][1][0],labels[k][1][1],:,:]\n",
    "                student1 -= np.mean(student1)\n",
    "                student2 -= np.mean(student2)\n",
    "                mini_batch[k - batch[0]][0] = student1.flatten()\n",
    "                mini_batch[k - batch[0]][1] = student2.flatten()\n",
    "            targets = np.array([0 if(labels[i][0][1] == labels[i][1][1]) else 1 for i in range(batch[0], batch[1])])\n",
    "            new_batch = mini_batch.reshape(batch[1] - batch[0], 2, 136, 1)\n",
    "            new_targets = targets.reshape(batch[1] - batch[0], 1)\n",
    "            #print(mini_batch.shape, targets.shape)\n",
    "            loss=siamese_net.train_on_batch(\n",
    "            {\n",
    "             'left': mini_batch[:, 0, :],\n",
    "             'right': mini_batch[:, 1, :]\n",
    "            },targets)\n",
    "            avg_loss += loss\n",
    "            track_loss['Epoch%s'%(i)].append(loss)\n",
    "        avg_loss = avg_loss/iterations\n",
    "        print('Epoch%s-----Loss: %f' %(i + 1, avg_loss))\n",
    "    return network, track_loss\n",
    "siamese_net, track_loss = train(data, ax,siamese_net, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNTM0JEnN/i9LzG213/ORvQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff1a3cd4e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotEvalSet(test, actual_data):\n",
    "    x = np.arange(0, 2)\n",
    "    for i in range(len(test)):\n",
    "        person1 = test[i][0]\n",
    "        person2 = test[i][1]\n",
    "        same = False\n",
    "        if(person1[1] == person2[1]):\n",
    "            same = True\n",
    "        prepx = actual_data[person1[0],person1[1],:,:]\n",
    "        prepy = actual_data[person2[0],person2[1],:,:]\n",
    "        student1 = prepx - np.mean(prepx)\n",
    "        student2 = prepy - np.mean(prepy)\n",
    "        student1 = student1.flatten()\n",
    "        student2 = student2.flatten()\n",
    "        out = siamese_net.predict({'left': student1.reshape(1, 136),\n",
    "                                    'right': student2.reshape(1, 136)\n",
    "                                    })\n",
    "        if(same):\n",
    "            plt.scatter(0, out[0][0])\n",
    "        else:\n",
    "            plt.scatter(1, out[0][0])\n",
    "    plt.xticks(x, ['Same', 'Different'])\n",
    "    plt.show()\n",
    "            \n",
    "plotEvalSet(x_test, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "def getFace_Cords(img_name):\n",
    "    image = cv2.imread(img_name)\n",
    "    image = imutils.resize(image, width=500)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "    \n",
    "    rects = detector(gray, 1)\n",
    "    shape = predictor(gray, rects[0])\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    return shape\n",
    "\n",
    "def computeAbsDifference(coords1, coords2):\n",
    "    metrics = []\n",
    "    if(coords1.shape != coords2.shape):\n",
    "        raise Exception('Coords need to be the same shape')\n",
    "    for i in range(0,2):\n",
    "        diff = np.abs(coords1[:, i] - coords2[:, i])\n",
    "        metrics.append(np.mean(diff))\n",
    "    return metrics\n",
    "\n",
    "def getPrediction(net, img1, img2):\n",
    "    coord1 = getFace_Cords(img1)\n",
    "    coord2 = getFace_Cords(img2)\n",
    "    coords1 = coord1 - np.mean(coord1)\n",
    "    coords2 = coord2 - np.mean(coord2)\n",
    "    coord1 = coords1.flatten()\n",
    "    coord2 = coords1.flatten()\n",
    "    return siamese_net.predict({'left': coord1.reshape(1, 136),\n",
    "                                'right': coord2.reshape(1, 136)\n",
    "                                })\n",
    "     #sum(computeAbsDifference(coords1, coords2))\n",
    "\n",
    "def getScores(net, combos):\n",
    "    scores = []\n",
    "    for i,j in combos:\n",
    "        scores.append([i[1], j[1], getPrediction(net, 'P%s/img%d.jpg'%(i[0] + 1,i[1] + 1), 'P%s//img%d.jpg'%(j[0] + 1,j[1] + 1))])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict =getPrediction(siamese_net, 'img21.jpg', 'P1/img1.jpg') #the higher the predict index, the greater the chance of the two \n",
    "                                                        #images being similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict1 = getPrediction(siamese_net, 'P4/img9.jpg', 'P3/img9.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict2 = getPrediction(siamese_net, 'img22.jpg', 'P3/img9.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_net.save_weights('my_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
